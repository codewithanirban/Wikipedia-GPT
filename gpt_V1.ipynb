{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o33_So55w-du"
      },
      "source": [
        "# Building a GPT\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azGWvprsxoMj"
      },
      "source": [
        "Importing the dataset from kaggle --- I've used Wikipedia Dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_na_RonwOso",
        "outputId": "23b81a09-7143-4be1-9cae-822d0f2c1470"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.7), please consider upgrading to the latest version (0.3.11).\n",
            "Path to dataset files: C:\\Users\\dccha\\.cache\\kagglehub\\datasets\\mikeortman\\wikipedia-sentences\\versions\\3\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"mikeortman/wikipedia-sentences\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGxmZiEFxvaw",
        "outputId": "c9f4cf1e-79a9-4b86-c486-9ef632eda8f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:\\Users\\dccha\\.cache\\kagglehub\\datasets\\mikeortman\\wikipedia-sentences\\versions\\3\\wikisent2.txt\n"
          ]
        }
      ],
      "source": [
        "# set the path dir\n",
        "import os\n",
        "base_path = os.path.join(path, 'wikisent2.txt')\n",
        "print(base_path)\n",
        "# read it in to inspect it\n",
        "with open(base_path,'r',encoding='utf-8') as f:\n",
        "  text = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDVkheFuyHX6",
        "outputId": "e4a297a4-efed-49a1-ea4c-e01cb1a5a519"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of dataset in characters:  934571982\n"
          ]
        }
      ],
      "source": [
        "print(\"Length of dataset in characters: \",len(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NlEuMFny1Pc",
        "outputId": "e64f15a6-a15f-4ebb-d05a-20f4e7ff1d04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.000123, which corresponds to a distance of 705 Mly, or 216 Mpc.\n",
            "000webhost is a free web hosting service, operated by Hostinger.\n",
            "0010x0010 is a Dutch-born audiovisual artist, currently living in Los Angeles.\n",
            "0-0-1-3 is an alcohol abuse prevention program developed in 2004 at Francis E. Warren Air Force Base based on research by the National Institute on Alcohol Abuse and Alcoholism regarding binge drinking in college students.\n",
            "0.01 is the debut studio album of H3llb3nt, released on February 20, 1996 by Fifth Colvmn Records.\n",
            "001 of 3 February 1997, which was signed between the Government of the Republic of Rwanda, and FAPADER.\n",
            "003230 is a South Korean food manufacturer.\n",
            "0.04%Gas molecules in soil are in continuous thermal motion according to the kinetic theory of gasses, there is also collision between molecules - a random walk.\n",
            "0.04% of the votes were invalid.\n",
            "005.1999.06 is the fifth studio album by the South Korean singer and actress Uhm Jung-hwa.\n",
            "005 is a 1981 arcade game by Sega.\n",
            "007 Legends is a first-person shooter video game featuring the character of British secret agent James Bond.\n",
            "007 Legends is the fourth and final James Bond game title released by Activision, the last game Eurocom developed before the company ceased operations and also the last James Bond video game to be available on home video game systems, to date.\n",
            "007 Racing is a racing video game based on the James Bond license.\n",
            "00 AM PST and burned a total of 8,110 acres.\n",
            "00am to 1:00pm on TV5, and it is the biggest project to date this year by the network and hosted by majority of the network's bunch of talents collectively known as \"HappyPeeps\".\n",
            "0.0 is a live album by Melt-Banana that came out on November 3, 2009.Melt-Banana perform some of their shows under the name Melt-Banana Lite, which means that they perform their music with a different arrangement.\n",
            "0.0% is considered to be the start of the retracement, while 100.0% is a complete reversal to the original part of the move.\n",
            "00 pm in daily g\n"
          ]
        }
      ],
      "source": [
        "# let us see the first 1500 characters\n",
        "print(text[:2000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVX5E0XCy8GG",
        "outputId": "7898e0fe-714f-4a7e-97d4-d484d21f00a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~\n",
            "Vocabulary size :  96\n"
          ]
        }
      ],
      "source": [
        "# listing the unique characters that occur in text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(''.join(chars))\n",
        "print(\"Vocabulary size : \",vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "443R9l20zQPm",
        "outputId": "85aef6b9-d01f-4ac0-ccc5-9e6c27ed4f7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[73, 70, 77, 77, 80, 1, 88, 80, 83, 77, 69]\n",
            "I am Anirban Chakraborty\n"
          ]
        }
      ],
      "source": [
        "# Mapping from characters to integers\n",
        "stoi = {ch:i for i,ch in enumerate(chars)}\n",
        "itos = {i:ch for i,ch in enumerate(chars)}\n",
        "# encoder: it will take the string and output a list of integer\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "# decoder: it will take the list of integer and output the string\n",
        "decode = lambda l: ''.join([itos[u] for u in l])\n",
        "\n",
        "print(encode('hello world'))\n",
        "print(decode(encode('I am Anirban Chakraborty')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyNl4E_T0Li3"
      },
      "outputs": [],
      "source": [
        "# Now let us encode the entire text dataset and store it in a Tensor\n",
        "# for this operation we will use torch.Tensor\n",
        "import torch\n",
        "data = torch.tensor(encode(text),dtype=torch.long)\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:2000]) #first 2000 characters after encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQca4VN61oSL"
      },
      "outputs": [],
      "source": [
        "# let us now split the data up into train and validation sets\n",
        "n = int(0.9*len(data)) # training on the first 90% , rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vgm2zGv2AEQ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([17, 15, 17, 17, 17, 18, 19, 20, 13])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "block_size = 8\n",
        "train_data[:block_size+1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "When input is tensor([17]), the target is 15\n",
            "When input is tensor([17, 15]), the target is 17\n",
            "When input is tensor([17, 15, 17]), the target is 17\n",
            "When input is tensor([17, 15, 17, 17]), the target is 17\n",
            "When input is tensor([17, 15, 17, 17, 17]), the target is 18\n",
            "When input is tensor([17, 15, 17, 17, 17, 18]), the target is 19\n",
            "When input is tensor([17, 15, 17, 17, 17, 18, 19]), the target is 20\n",
            "When input is tensor([17, 15, 17, 17, 17, 18, 19, 20]), the target is 13\n"
          ]
        }
      ],
      "source": [
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "for t in range(block_size):\n",
        "    context = x[:t+1]\n",
        "    target = y[t]\n",
        "    print(f\"When input is {context}, the target is {target}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
